{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Deploying Driverless AI Models to Production \u00b6 This documentation lists some of the scenarios to deploy Driverless AI models to production and provides guidlines to create deployment templates for the same. The final model from a Driverless AI experiment can be exported as either a MOJO scoring pipeline or a Python scoring pipeline . The Mojo scoring pipeline comes with a pipline.mojo file with a Java or C++ runtime. This can be deployed in any environment that supports Java or C++. The Python scoring pipeline comes with the scoring whl file for deployment purposes. Below, is a list of the deployment scenerios for Driverless AI pipelines for Real-time, Batch or Stream scoring. graph LR; A[\"Realtime Scoring (single or multi-rows)\"]-->AA[DAI MOJO Pipeline with Java Runtime]; A-->AB[DAI MOJO Pipeline with C++ Runtime]; A-->AC[DAI PYTHON Scoring Pipeline]; AA-->AAA[\"As REST Server\"] AA-->AAB[\"As AWS Lambda\"] AA-->AAC[\"As GCP Cloud Run\"] AA-->AAD[\"As AzureML\"] AA-->AAE[\"As library\"] AA-->AAF[\"As Nifi \"] AB-->ABA[\"As library\"] AB-->ABB[\"As Nifi \"] AC-->ACA[\"As REST Server\"] AC-->ACB[\"As Nifi \"] classDef className fill:#f9f,stroke:#333,stroke-width:4px; class A,AA,AB className; graph LR; A[\"Batch Scoring\"]-->AA[DAI MOJO Pipeline with Java Runtime]; A-->AB[DAI MOJO Pipeline with C++ Runtime]; A-->AC[DAI PYTHON Scoring Pipeline]; AA-->AAA[\"As Spark batch\"] AA-->AAB[\"As library\"] AA-->AAC[\"As Hive UDF\"] AA-->AAD[\"As DB scorer\"] AA-->AAE[\"As Nifi\"] AB-->ABA[\"As library\"] AB-->ABB[\"As Nifi \"] AC-->ACA[\"As library\"] AC-->ACB[\"As Nifi \"] classDef className fill:#f9f,stroke:#333,stroke-width:4px; style A fill:#FFFFCC class start,A,AA,AB className; graph LR; A[\"Stream Scoring\"]-->AA[DAI MOJO Pipeline with Java Runtime]; AA-->AAA[\"As Spark Stream\"] AA-->AAB[\"As Task Queue \"] AA-->AAC[\"As Active MQ\"] AA-->AAD[\"As Kafka Topic\"] classDef className fill:#f9f,stroke:#333,stroke-width:4px; style A fill:#FFFFCC class start,A,AA,AB className;","title":"Overview"},{"location":"#deploying-driverless-ai-models-to-production","text":"This documentation lists some of the scenarios to deploy Driverless AI models to production and provides guidlines to create deployment templates for the same. The final model from a Driverless AI experiment can be exported as either a MOJO scoring pipeline or a Python scoring pipeline . The Mojo scoring pipeline comes with a pipline.mojo file with a Java or C++ runtime. This can be deployed in any environment that supports Java or C++. The Python scoring pipeline comes with the scoring whl file for deployment purposes. Below, is a list of the deployment scenerios for Driverless AI pipelines for Real-time, Batch or Stream scoring. graph LR; A[\"Realtime Scoring (single or multi-rows)\"]-->AA[DAI MOJO Pipeline with Java Runtime]; A-->AB[DAI MOJO Pipeline with C++ Runtime]; A-->AC[DAI PYTHON Scoring Pipeline]; AA-->AAA[\"As REST Server\"] AA-->AAB[\"As AWS Lambda\"] AA-->AAC[\"As GCP Cloud Run\"] AA-->AAD[\"As AzureML\"] AA-->AAE[\"As library\"] AA-->AAF[\"As Nifi \"] AB-->ABA[\"As library\"] AB-->ABB[\"As Nifi \"] AC-->ACA[\"As REST Server\"] AC-->ACB[\"As Nifi \"] classDef className fill:#f9f,stroke:#333,stroke-width:4px; class A,AA,AB className; graph LR; A[\"Batch Scoring\"]-->AA[DAI MOJO Pipeline with Java Runtime]; A-->AB[DAI MOJO Pipeline with C++ Runtime]; A-->AC[DAI PYTHON Scoring Pipeline]; AA-->AAA[\"As Spark batch\"] AA-->AAB[\"As library\"] AA-->AAC[\"As Hive UDF\"] AA-->AAD[\"As DB scorer\"] AA-->AAE[\"As Nifi\"] AB-->ABA[\"As library\"] AB-->ABB[\"As Nifi \"] AC-->ACA[\"As library\"] AC-->ACB[\"As Nifi \"] classDef className fill:#f9f,stroke:#333,stroke-width:4px; style A fill:#FFFFCC class start,A,AA,AB className; graph LR; A[\"Stream Scoring\"]-->AA[DAI MOJO Pipeline with Java Runtime]; AA-->AAA[\"As Spark Stream\"] AA-->AAB[\"As Task Queue \"] AA-->AAC[\"As Active MQ\"] AA-->AAD[\"As Kafka Topic\"] classDef className fill:#f9f,stroke:#333,stroke-width:4px; style A fill:#FFFFCC class start,A,AA,AB className;","title":"Deploying Driverless AI Models to Production"},{"location":"aws-sagemaker-hosted-scorer/","text":"Driverless AI Deployment Template for AWS Sagemaker Hosted Scorer \u00b6 This template scores realtime data using Driverless AI Mojo pipeline with Java Runtime and plugs into the AWS SageMaker workflow documented here It is a REST API which accepts one data point at a time for prediction in real-time in the hosted SageMaker environment. The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring, see deploy section for details. The versions of software used to create the template like mojo runtime are listed here . Overview \u00b6 Build Image \u00b6 Generation of the Docker image is plugged into the build process of this project. Run the following command in the root project directory to run the build process. ./gradlew :aws-sagemaker-hosted-scorer:jibDockerBuild Verify that the Docker image was created, and take note of the version created. docker images --format \"{{.Repository}} \\t {{.Tag}}\" | grep \"h2oai/sagemaker-hosted-scorer\" Optional: Test the build \u00b6 After building, run to test the produced Docker container locally like this: Step 1: Put a pipeline.mojo and valid license.sig into this directory (aws-sagemaker-hosted-scorer). Step 2: Start the docker instance. docker run \\ --rm \\ --init \\ -ti \\ -v `pwd`:/opt/ml/model \\ -p 8080:8080 \\ harbor.h2o.ai/opsh2oai/h2oai/sagemaker-hosted-scorer \\ serve Step 3: Use curl to send a JSON-formatted row to the scorer as shown in the details below. Deploy to SageMaker \u00b6 Create h2oai/sagemaker-hosted-scorer repository in Sagemaker for the scorer service image. Use the output of the command below to docker login : aws ecr get-login --region <region> --no-include-email Tag the scorer service image for loading into the h2oai/sagemaker-hosted-scorer repository. docker tag <IMAGE ID> <aws_account_id>.dkr.ecr.<region>.amazonaws.com/h2oai/sagemaker-hosted-scorer Then push the scorer service image to AWS ECR (Elastic Container Registry): docker push <aws_account_id>.dkr.ecr.<region>.amazonaws.com/h2oai/sagemaker-hosted-scorer Then create a model package with the pipeline file and the license key, and copy it to S3: tar cvf mojo.tar pipeline.mojo license.sig gzip mojo.tar aws s3 cp mojo.tar.gz s3://<your-bucket>/ Next create the appropriate model and endpoint on Sagemaker. Check that the endpoint is available with aws sagemaker list-endpoints . Examples \u00b6 There is the examples directory, which houses a sample python notebook, which utilizes the AWS Sagemaker SDK to deploy a Sagemaker model pythonically. See the notebook here For an example of an endpoint query being made via Python go here Details \u00b6 AWS Model Creation API \u00b6 https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateModel.html CreateEndpoint Environment DRIVERLESS_AI_LICENSE_KEY=base64key ModelDataURL=s3://blah/blah/model.tar.gz DRIVERLESS_AI_LICENSE_KEY environment variable must contain the base64-encoded key (optional if a license.sig isns't included in mojo.tar.gz) ModelDataURL must point to an S3 URL with a .tar.gz file of the MOJO artifact Docker container \u00b6 The docker container produced in this directory conforms to the specification described here: https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-code-run-image Sagemaker starts the container with the following command: docker run image serve Our container consists of the following entrypoint: ENTRYPOINT [\"java\", \"-jar\", \"serve.jar\"] Example Predictions \u00b6 You can test the container locally with the following curl command: curl \\ -X POST \\ -H \"Content-Type: application/json\" \\ -d @test.json http://localhost:8080/invocations test.json: { \"fields\": [ \"field1\", \"field2\" ], \"includeFieldsInOutput\": [ \"field2\" ], \"rows\": [ [ \"value1\", \"value2\" ], [ \"value1\", \"value2\" ] ] }","title":"AWS Sagemaker Hosted Scorer"},{"location":"aws-sagemaker-hosted-scorer/#driverless-ai-deployment-template-for-aws-sagemaker-hosted-scorer","text":"This template scores realtime data using Driverless AI Mojo pipeline with Java Runtime and plugs into the AWS SageMaker workflow documented here It is a REST API which accepts one data point at a time for prediction in real-time in the hosted SageMaker environment. The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring, see deploy section for details. The versions of software used to create the template like mojo runtime are listed here .","title":"Driverless AI Deployment Template for AWS Sagemaker Hosted Scorer"},{"location":"aws-sagemaker-hosted-scorer/#overview","text":"","title":"Overview"},{"location":"aws-sagemaker-hosted-scorer/#build-image","text":"Generation of the Docker image is plugged into the build process of this project. Run the following command in the root project directory to run the build process. ./gradlew :aws-sagemaker-hosted-scorer:jibDockerBuild Verify that the Docker image was created, and take note of the version created. docker images --format \"{{.Repository}} \\t {{.Tag}}\" | grep \"h2oai/sagemaker-hosted-scorer\"","title":"Build Image"},{"location":"aws-sagemaker-hosted-scorer/#optional-test-the-build","text":"After building, run to test the produced Docker container locally like this: Step 1: Put a pipeline.mojo and valid license.sig into this directory (aws-sagemaker-hosted-scorer). Step 2: Start the docker instance. docker run \\ --rm \\ --init \\ -ti \\ -v `pwd`:/opt/ml/model \\ -p 8080:8080 \\ harbor.h2o.ai/opsh2oai/h2oai/sagemaker-hosted-scorer \\ serve Step 3: Use curl to send a JSON-formatted row to the scorer as shown in the details below.","title":"Optional: Test the build"},{"location":"aws-sagemaker-hosted-scorer/#deploy-to-sagemaker","text":"Create h2oai/sagemaker-hosted-scorer repository in Sagemaker for the scorer service image. Use the output of the command below to docker login : aws ecr get-login --region <region> --no-include-email Tag the scorer service image for loading into the h2oai/sagemaker-hosted-scorer repository. docker tag <IMAGE ID> <aws_account_id>.dkr.ecr.<region>.amazonaws.com/h2oai/sagemaker-hosted-scorer Then push the scorer service image to AWS ECR (Elastic Container Registry): docker push <aws_account_id>.dkr.ecr.<region>.amazonaws.com/h2oai/sagemaker-hosted-scorer Then create a model package with the pipeline file and the license key, and copy it to S3: tar cvf mojo.tar pipeline.mojo license.sig gzip mojo.tar aws s3 cp mojo.tar.gz s3://<your-bucket>/ Next create the appropriate model and endpoint on Sagemaker. Check that the endpoint is available with aws sagemaker list-endpoints .","title":"Deploy to SageMaker"},{"location":"aws-sagemaker-hosted-scorer/#examples","text":"There is the examples directory, which houses a sample python notebook, which utilizes the AWS Sagemaker SDK to deploy a Sagemaker model pythonically. See the notebook here For an example of an endpoint query being made via Python go here","title":"Examples"},{"location":"aws-sagemaker-hosted-scorer/#details","text":"","title":"Details"},{"location":"aws-sagemaker-hosted-scorer/#aws-model-creation-api","text":"https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateModel.html CreateEndpoint Environment DRIVERLESS_AI_LICENSE_KEY=base64key ModelDataURL=s3://blah/blah/model.tar.gz DRIVERLESS_AI_LICENSE_KEY environment variable must contain the base64-encoded key (optional if a license.sig isns't included in mojo.tar.gz) ModelDataURL must point to an S3 URL with a .tar.gz file of the MOJO artifact","title":"AWS Model Creation API"},{"location":"aws-sagemaker-hosted-scorer/#docker-container","text":"The docker container produced in this directory conforms to the specification described here: https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html#your-algorithms-inference-code-run-image Sagemaker starts the container with the following command: docker run image serve Our container consists of the following entrypoint: ENTRYPOINT [\"java\", \"-jar\", \"serve.jar\"]","title":"Docker container"},{"location":"aws-sagemaker-hosted-scorer/#example-predictions","text":"You can test the container locally with the following curl command: curl \\ -X POST \\ -H \"Content-Type: application/json\" \\ -d @test.json http://localhost:8080/invocations test.json: { \"fields\": [ \"field1\", \"field2\" ], \"includeFieldsInOutput\": [ \"field2\" ], \"rows\": [ [ \"value1\", \"value2\" ], [ \"value1\", \"value2\" ] ] }","title":"Example Predictions"},{"location":"aws_lambda_scorer/","text":"Driverless AI MOJO pipeline Deployment Template for AWS Lambda \u00b6 This template contains scorer implementation for Driverless AI Model MOJO pipiline with Java runtime on AWS Lambda and can be used to do Real-time scoring on single or multiple rows. The structure is as follows: Source of the generic lambda implementation in: lambda-template Parameterized terraform files for pushing the lambda to AWS in: terraform-recipe The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring. The versions of software used to create the template like mojo runtime are listed here . Building the lambda-template \u00b6 The code of the AWS Lambda scorer is a gradle project build as usual by ./gradlew build . The build result is a Zip archive lambda-template/build/distributions/lambda-template.zip containing a general Mojo scorer that can be directly pushed to AWS. The Scorer relies on the following environment variables: DEPLOYMENT_S3_BUCKET_NAME : Name of the AWS S3 bucket storing the Mojo file. MOJO_S3_OBJECT_KEY : Key of Driverless AI model Mojo file (pipeline.mojo) AWS S3 object. DRIVERLESS_AI_LICENSE_KEY : The Driverless license key. Pushing to AWS Using Terraform \u00b6 This deployment template is meant to be used by Driverless AI backend directly, not by hand. The following describes step necessary to push the lambda by hand, e.g., for testing purposes. One-off Setup \u00b6 Install terraform 0.11.10 following steps in: https://www.terraform.io/downloads.html. Initialize terraform by running terraform init in the terraform-recipe folder. This will download all necessary Terraform plugins, e.g., the AWS one. Pushing Lambda to AWS \u00b6 The Terraform recipe in terraform-recipe relies on a few variables you need to provide either by hand, from command line, or by setting corresponding environmental variables (using the prefix TF_VAR_ ): access_key : The access key to your AWS account. secret_key : The secret key to your AWS account. region : AWS region to push to (optional, defaults to us-east-1 ). lambda_id : Id of the resulting AWS lambda. Keep that unique as it is also used to store other fragments, e.g., the Mojo file in S3. lambda_zip_path : Local path to the actual lambda scorer distribution, see above (optional, defaults to the relative path to the build Zip archive above). mojo_path : Local path to the mojo file to be pushed to S3. You may get one, e.g., by running Driverless AI on test/data/iris.csv and asking it to create and download the Mojo scoring pipeline in the UI. license_key : Driverless AI license key. bucket_name : Name of AWS S3 bucket to store the mojo to so that the lambda can access and load it. Note that the bucket has to already exist and the effective AWS account has to have write access to it. Once all the non-optional variables are set, the following command will push the lambda (or update any changes thereof): terraform apply . Upon successful push, Terraform will output the URL of the lambda endpoint and the corresponding api_key . Note that the recipe sets up AWS API Gateway proxy, see api_gateway.tf . Look for base_url and api_key in the output. Outputs: api_key = DXQtiCbqEY6xjXWP1MMCu4nkDTwRgfdX2qZoKm3e base_url = https://mslmi91tni.execute-api.us-east-1.amazonaws.com/test Example Prediction \u00b6 To test the endpoint, send a request to this URL appended by score and include the api_key in the request header x-api-key , e.g., as follows. $ curl \\ -X POST \\ -H \"x-api-key: DXQtiCbqEY6xjXWP1MMCu4nkDTwRgfdX2qZoKm3e\" \\ -d @test.json https://mslmi91tni.execute-api.us-east-1.amazonaws.com/test/score This expects a file test.json with the actual scoring request payload. If you are using the mojo trained in test/data/iris.csv as suggested above, you should be able to use the following json payload: { \"fields\": [ \"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\" ], \"includeFieldsInOutput\": [ \"sepal_len\" ], \"rows\": [ [ \"1.0\", \"1.0\", \"2.2\", \"3.5\" ], [ \"3.0\", \"10.0\", \"2.2\", \"3.5\" ], [ \"4.0\", \"100.0\", \"2.2\", \"3.5\" ] ] } The expected response should follow this structure: { \"id\": \"a12e7390-b8ac-406a-ade9-0d5ea4b63ea9\", \"fields\": [ \"sepal_len\", \"class.Iris-setosa\", \"class.Iris-versicolor\", \"class.Iris-virginica\" ], \"score\": [ [ \"1.0\", \"0.6240277982943945\", \"0.045458571508101536\", \"0.330513630197504\" ], [ \"3.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ], [ \"4.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ] ] } Note that including the fields in the response can be disabled by setting noFieldNamesInOutput to true in the input request.","title":"AWS Lambda Scorer"},{"location":"aws_lambda_scorer/#driverless-ai-mojo-pipeline-deployment-template-for-aws-lambda","text":"This template contains scorer implementation for Driverless AI Model MOJO pipiline with Java runtime on AWS Lambda and can be used to do Real-time scoring on single or multiple rows. The structure is as follows: Source of the generic lambda implementation in: lambda-template Parameterized terraform files for pushing the lambda to AWS in: terraform-recipe The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring. The versions of software used to create the template like mojo runtime are listed here .","title":"Driverless AI MOJO pipeline Deployment Template for AWS Lambda"},{"location":"aws_lambda_scorer/#building-the-lambda-template","text":"The code of the AWS Lambda scorer is a gradle project build as usual by ./gradlew build . The build result is a Zip archive lambda-template/build/distributions/lambda-template.zip containing a general Mojo scorer that can be directly pushed to AWS. The Scorer relies on the following environment variables: DEPLOYMENT_S3_BUCKET_NAME : Name of the AWS S3 bucket storing the Mojo file. MOJO_S3_OBJECT_KEY : Key of Driverless AI model Mojo file (pipeline.mojo) AWS S3 object. DRIVERLESS_AI_LICENSE_KEY : The Driverless license key.","title":"Building the lambda-template"},{"location":"aws_lambda_scorer/#pushing-to-aws-using-terraform","text":"This deployment template is meant to be used by Driverless AI backend directly, not by hand. The following describes step necessary to push the lambda by hand, e.g., for testing purposes.","title":"Pushing to AWS Using Terraform"},{"location":"aws_lambda_scorer/#one-off-setup","text":"Install terraform 0.11.10 following steps in: https://www.terraform.io/downloads.html. Initialize terraform by running terraform init in the terraform-recipe folder. This will download all necessary Terraform plugins, e.g., the AWS one.","title":"One-off Setup"},{"location":"aws_lambda_scorer/#pushing-lambda-to-aws","text":"The Terraform recipe in terraform-recipe relies on a few variables you need to provide either by hand, from command line, or by setting corresponding environmental variables (using the prefix TF_VAR_ ): access_key : The access key to your AWS account. secret_key : The secret key to your AWS account. region : AWS region to push to (optional, defaults to us-east-1 ). lambda_id : Id of the resulting AWS lambda. Keep that unique as it is also used to store other fragments, e.g., the Mojo file in S3. lambda_zip_path : Local path to the actual lambda scorer distribution, see above (optional, defaults to the relative path to the build Zip archive above). mojo_path : Local path to the mojo file to be pushed to S3. You may get one, e.g., by running Driverless AI on test/data/iris.csv and asking it to create and download the Mojo scoring pipeline in the UI. license_key : Driverless AI license key. bucket_name : Name of AWS S3 bucket to store the mojo to so that the lambda can access and load it. Note that the bucket has to already exist and the effective AWS account has to have write access to it. Once all the non-optional variables are set, the following command will push the lambda (or update any changes thereof): terraform apply . Upon successful push, Terraform will output the URL of the lambda endpoint and the corresponding api_key . Note that the recipe sets up AWS API Gateway proxy, see api_gateway.tf . Look for base_url and api_key in the output. Outputs: api_key = DXQtiCbqEY6xjXWP1MMCu4nkDTwRgfdX2qZoKm3e base_url = https://mslmi91tni.execute-api.us-east-1.amazonaws.com/test","title":"Pushing Lambda to AWS"},{"location":"aws_lambda_scorer/#example-prediction","text":"To test the endpoint, send a request to this URL appended by score and include the api_key in the request header x-api-key , e.g., as follows. $ curl \\ -X POST \\ -H \"x-api-key: DXQtiCbqEY6xjXWP1MMCu4nkDTwRgfdX2qZoKm3e\" \\ -d @test.json https://mslmi91tni.execute-api.us-east-1.amazonaws.com/test/score This expects a file test.json with the actual scoring request payload. If you are using the mojo trained in test/data/iris.csv as suggested above, you should be able to use the following json payload: { \"fields\": [ \"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\" ], \"includeFieldsInOutput\": [ \"sepal_len\" ], \"rows\": [ [ \"1.0\", \"1.0\", \"2.2\", \"3.5\" ], [ \"3.0\", \"10.0\", \"2.2\", \"3.5\" ], [ \"4.0\", \"100.0\", \"2.2\", \"3.5\" ] ] } The expected response should follow this structure: { \"id\": \"a12e7390-b8ac-406a-ade9-0d5ea4b63ea9\", \"fields\": [ \"sepal_len\", \"class.Iris-setosa\", \"class.Iris-versicolor\", \"class.Iris-virginica\" ], \"score\": [ [ \"1.0\", \"0.6240277982943945\", \"0.045458571508101536\", \"0.330513630197504\" ], [ \"3.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ], [ \"4.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ] ] } Note that including the fields in the response can be disabled by setting noFieldNamesInOutput to true in the input request.","title":"Example Prediction"},{"location":"gcp/","text":"Driverless AI Deployment Template for Google Cloud Run \u00b6 This template extends the implementation of Local Rest Scorer here and scores data using Driverless AI Mojo pipeline with Java Runtime. The docker image that is built by this project can be pushed to gcr.io and used for scoring Driverless AI Mojos in Google Cloud Run . The user needs to provide Driverless AI license key and model's pipeline.mojo file as input for scoring. The versions of software used to create the template like mojo runtime are listed here . Building \u00b6 Since there is a direct dependency on the separate, above mentioned project local-rest-scorer it is best to build this project from the root directory. Make sure you are in the working directory dai-deployment-templates . Typing pwd in the terminal shell should have a similar output to /my/path/to/dai-deployment-templates . Run the following command: ./gradlew build and the docker image required for Google Cloud Run will be in the directory gcp-cloud-run/build : /path/to/dai-deployment-templates/gcp-cloud-run/build/jib-image.tar Load the resulting jib-image.tar file to docker: docker load < /path/to/dai-deployment-templates/gcp-cloud-run/build/jib-image.tar Follow the steps explained here in Google Documentation: https://cloud.google.com/run/docs/building/containers, to push the container to gcr.io Deploying \u00b6 To deploy the container follow the steps in Google Documentation here: https://cloud.google.com/run/docs/deploying There is one requirement for the container. You MUST include the following environment variables: MOJO_GCS_PATH = gs://path/to/pipeline.mojo LICENSE_GCS_PATH = gs://path/to/driverless/ai/license.sig Scoring \u00b6 On a successful deployment to Google Cloud Run, you will be provided an endpoint that can be scored against. The api for scoring is the same as the Local Rest Scorer To access api information: https://<google provided endpoint>/swagger-ui.html To score the model: https://<google provided endpoint>/model/score Sample curl request: curl -X POST -H \"Content-Type: application/json\" \\ -d '{\"includeFieldsInOutput\":null,\"noFieldNamesInOutput\":null,\"idField\":null, \\ \"fields\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_1\",\"PAY_2\", \\ \"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\", \\ \"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\", \\ \"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"], \\ \"rows\":[[\"0\",\"text\",\"text\",\"text\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\"]]}' \\ https://<google provided endpoint>/model/score","title":"Google Cloud Run Scorer"},{"location":"gcp/#driverless-ai-deployment-template-for-google-cloud-run","text":"This template extends the implementation of Local Rest Scorer here and scores data using Driverless AI Mojo pipeline with Java Runtime. The docker image that is built by this project can be pushed to gcr.io and used for scoring Driverless AI Mojos in Google Cloud Run . The user needs to provide Driverless AI license key and model's pipeline.mojo file as input for scoring. The versions of software used to create the template like mojo runtime are listed here .","title":"Driverless AI Deployment Template for Google Cloud Run"},{"location":"gcp/#building","text":"Since there is a direct dependency on the separate, above mentioned project local-rest-scorer it is best to build this project from the root directory. Make sure you are in the working directory dai-deployment-templates . Typing pwd in the terminal shell should have a similar output to /my/path/to/dai-deployment-templates . Run the following command: ./gradlew build and the docker image required for Google Cloud Run will be in the directory gcp-cloud-run/build : /path/to/dai-deployment-templates/gcp-cloud-run/build/jib-image.tar Load the resulting jib-image.tar file to docker: docker load < /path/to/dai-deployment-templates/gcp-cloud-run/build/jib-image.tar Follow the steps explained here in Google Documentation: https://cloud.google.com/run/docs/building/containers, to push the container to gcr.io","title":"Building"},{"location":"gcp/#deploying","text":"To deploy the container follow the steps in Google Documentation here: https://cloud.google.com/run/docs/deploying There is one requirement for the container. You MUST include the following environment variables: MOJO_GCS_PATH = gs://path/to/pipeline.mojo LICENSE_GCS_PATH = gs://path/to/driverless/ai/license.sig","title":"Deploying"},{"location":"gcp/#scoring","text":"On a successful deployment to Google Cloud Run, you will be provided an endpoint that can be scored against. The api for scoring is the same as the Local Rest Scorer To access api information: https://<google provided endpoint>/swagger-ui.html To score the model: https://<google provided endpoint>/model/score Sample curl request: curl -X POST -H \"Content-Type: application/json\" \\ -d '{\"includeFieldsInOutput\":null,\"noFieldNamesInOutput\":null,\"idField\":null, \\ \"fields\":[\"LIMIT_BAL\",\"SEX\",\"EDUCATION\",\"MARRIAGE\",\"AGE\",\"PAY_1\",\"PAY_2\", \\ \"PAY_3\",\"PAY_4\",\"PAY_5\",\"PAY_6\",\"BILL_AMT1\",\"BILL_AMT2\",\"BILL_AMT3\", \\ \"BILL_AMT4\",\"BILL_AMT5\",\"BILL_AMT6\",\"PAY_AMT1\",\"PAY_AMT2\",\"PAY_AMT3\", \\ \"PAY_AMT4\",\"PAY_AMT5\",\"PAY_AMT6\"], \\ \"rows\":[[\"0\",\"text\",\"text\",\"text\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\"]]}' \\ https://<google provided endpoint>/model/score","title":"Scoring"},{"location":"local-rest-scorer/","text":"Driverless AI Deployment Template for Local SpringBoot Scorer \u00b6 This template contains sources of a generic Java scorer implementation for Driverless AI MOJO scoring pipiline with Java runtime , based on SpringBoot and its Docker image. This scorer can be used to do Real-time scoring on single or multiple rows. The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring. The versions of software used to create the template like mojo runtime are listed here . Building \u00b6 The code of the local SpringBoot scorer is a gradle project build as usual by ./gradlew build . The resulting executable jar is located in the build/libs folder. Running \u00b6 To run the local scorer, you can either use bootRun gradle task or run directly the executable jar: java -Dmojo.path={PATH_TO_MOJO_PIPELINE} -jar build/libs/local-rest-scorer-{YOUR_CURRENT_VERSION}-boot.jar Score JSON Request \u00b6 To test the endpoint, send a request to http://localhost:8080 as follows: curl \\ -X POST \\ -H \"Content-Type: application/json\" \\ -d @test.json http://localhost:8080/model/score This expects a file test.json with the actual scoring request payload. If you are using the mojo trained in test/data/iris.csv as suggested above, you should be able to use the following json payload: { \"fields\": [ \"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\" ], \"includeFieldsInOutput\": [ \"sepal_len\" ], \"rows\": [ [ \"1.0\", \"1.0\", \"2.2\", \"3.5\" ], [ \"3.0\", \"10.0\", \"2.2\", \"3.5\" ], [ \"4.0\", \"100.0\", \"2.2\", \"3.5\" ] ] } The expected response should follow this structure, but the actual values may differ: { \"id\": \"a12e7390-b8ac-406a-ade9-0d5ea4b63ea9\", \"fields\": [ \"sepal_len\", \"class.Iris-setosa\", \"class.Iris-versicolor\", \"class.Iris-virginica\" ], \"score\": [ [ \"1.0\", \"0.6240277982943945\", \"0.045458571508101536\", \"0.330513630197504\" ], [ \"3.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ], [ \"4.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ] ] } Note that including the fields in the response can be disabled by setting noFieldNamesInOutput to true in the input request. Score CSV File \u00b6 Alternatively, you can score an existing file on the local filesystem using GET request to the same endpoint: curl -X GET http://localhost:8080/model/score/?file=/tmp/test.csv This expects a CSV file /tmp/test.csv to exist on the machine where the scorer runs (i.e., it is not send to it over HTTP). Model ID \u00b6 You can get the UUID of the loaded pipeline by calling the following: $ curl http://localhost:8080/model/id Which should return the UUID of the loaded mojo model. Alternatively, the scorer log contains the UUID as well in the form: Mojo pipeline successfully loaded (a12e7390-b8ac-406a-ade9-0d5ea4b63ea9). The hex string in parenthesis is the UUID of you mojo pipeline. Get Example Request \u00b6 The scorer can also provide an example request that would pass all validations. This way, users can quickly get an example scoring request to send to the scorer to test it. This request can be further filled with meaningful input values. curl -X GET http://localhost:8080/model/sample_request The resulting JSON is a valid input for the POST /model/score request. API Inspection \u00b6 You can use SpringFox endpoints that allow both programmatic and manual inspection of the API: Swagger JSON representation for programmatic access: http://localhost:8080/v2/api-docs. The UI for manual API inspection: http://localhost:8080/swagger-ui.html. Docker Image \u00b6 Docker image for this REST scorer is built using Jib . Build Image \u00b6 Generation of this Docker image is plugged into the build process of this project. Run the following command in the root project directory to run the build process. ./gradlew :local-rest-scorer:jibDockerBuild Verify that the Docker image was created, and take note of the version created. docker images --format \"{{.Repository}} \\t {{.Tag}}\" | grep \"h2oai/rest-scorer\" Run Container \u00b6 Note: Replace <version> with the version of the image you found from the previous step. docker run \\ --name rest-scorer \\ -v /path/to/local/pipeline.mojo:/mojos/pipeline.mojo:ro \\ -v /path/to/local/license.sig:/secrets/license.sig:ro \\ -p 8080:8080 \\ h2oai/rest-scorer:<version> Notice how the desired MOJO was mounted to the container: -v /path/to/local/pipeline.mojo:/mojos/pipeline.mojo:ro Notice how your H2O.ai DriverlessAI license was mounted to the container: -v /path/to/local/license.sig:/secrets/license.sig:ro Alternatively, you could pass in your license as an environment variable: First, export your license key. read -s DRIVERLESS_AI_LICENSE_KEY < /path/to/local/license.sig export DRIVERLESS_AI_LICENSE_KEY Note: Option -s , above, hides the echoing of your license so that its content is not written to logs. Now start a container. docker run \\ --name rest-scorer \\ -v /path/to/local/pipeline.mojo:/mojos/pipeline.mojo:ro \\ -e DRIVERLESS_AI_LICENSE_KEY \\ -p 8080:8080 \\ h2oai/rest-scorer:<version> See section Running above for information on how to score requests.","title":"Local Rest Server Scorer"},{"location":"local-rest-scorer/#driverless-ai-deployment-template-for-local-springboot-scorer","text":"This template contains sources of a generic Java scorer implementation for Driverless AI MOJO scoring pipiline with Java runtime , based on SpringBoot and its Docker image. This scorer can be used to do Real-time scoring on single or multiple rows. The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring. The versions of software used to create the template like mojo runtime are listed here .","title":"Driverless AI Deployment Template for Local SpringBoot Scorer"},{"location":"local-rest-scorer/#building","text":"The code of the local SpringBoot scorer is a gradle project build as usual by ./gradlew build . The resulting executable jar is located in the build/libs folder.","title":"Building"},{"location":"local-rest-scorer/#running","text":"To run the local scorer, you can either use bootRun gradle task or run directly the executable jar: java -Dmojo.path={PATH_TO_MOJO_PIPELINE} -jar build/libs/local-rest-scorer-{YOUR_CURRENT_VERSION}-boot.jar","title":"Running"},{"location":"local-rest-scorer/#score-json-request","text":"To test the endpoint, send a request to http://localhost:8080 as follows: curl \\ -X POST \\ -H \"Content-Type: application/json\" \\ -d @test.json http://localhost:8080/model/score This expects a file test.json with the actual scoring request payload. If you are using the mojo trained in test/data/iris.csv as suggested above, you should be able to use the following json payload: { \"fields\": [ \"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\" ], \"includeFieldsInOutput\": [ \"sepal_len\" ], \"rows\": [ [ \"1.0\", \"1.0\", \"2.2\", \"3.5\" ], [ \"3.0\", \"10.0\", \"2.2\", \"3.5\" ], [ \"4.0\", \"100.0\", \"2.2\", \"3.5\" ] ] } The expected response should follow this structure, but the actual values may differ: { \"id\": \"a12e7390-b8ac-406a-ade9-0d5ea4b63ea9\", \"fields\": [ \"sepal_len\", \"class.Iris-setosa\", \"class.Iris-versicolor\", \"class.Iris-virginica\" ], \"score\": [ [ \"1.0\", \"0.6240277982943945\", \"0.045458571508101536\", \"0.330513630197504\" ], [ \"3.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ], [ \"4.0\", \"0.7209441819603676\", \"0.06299909138586585\", \"0.21605672665376663\" ] ] } Note that including the fields in the response can be disabled by setting noFieldNamesInOutput to true in the input request.","title":"Score JSON Request"},{"location":"local-rest-scorer/#score-csv-file","text":"Alternatively, you can score an existing file on the local filesystem using GET request to the same endpoint: curl -X GET http://localhost:8080/model/score/?file=/tmp/test.csv This expects a CSV file /tmp/test.csv to exist on the machine where the scorer runs (i.e., it is not send to it over HTTP).","title":"Score CSV File"},{"location":"local-rest-scorer/#model-id","text":"You can get the UUID of the loaded pipeline by calling the following: $ curl http://localhost:8080/model/id Which should return the UUID of the loaded mojo model. Alternatively, the scorer log contains the UUID as well in the form: Mojo pipeline successfully loaded (a12e7390-b8ac-406a-ade9-0d5ea4b63ea9). The hex string in parenthesis is the UUID of you mojo pipeline.","title":"Model ID"},{"location":"local-rest-scorer/#get-example-request","text":"The scorer can also provide an example request that would pass all validations. This way, users can quickly get an example scoring request to send to the scorer to test it. This request can be further filled with meaningful input values. curl -X GET http://localhost:8080/model/sample_request The resulting JSON is a valid input for the POST /model/score request.","title":"Get Example Request"},{"location":"local-rest-scorer/#api-inspection","text":"You can use SpringFox endpoints that allow both programmatic and manual inspection of the API: Swagger JSON representation for programmatic access: http://localhost:8080/v2/api-docs. The UI for manual API inspection: http://localhost:8080/swagger-ui.html.","title":"API Inspection"},{"location":"local-rest-scorer/#docker-image","text":"Docker image for this REST scorer is built using Jib .","title":"Docker Image"},{"location":"local-rest-scorer/#build-image","text":"Generation of this Docker image is plugged into the build process of this project. Run the following command in the root project directory to run the build process. ./gradlew :local-rest-scorer:jibDockerBuild Verify that the Docker image was created, and take note of the version created. docker images --format \"{{.Repository}} \\t {{.Tag}}\" | grep \"h2oai/rest-scorer\"","title":"Build Image"},{"location":"local-rest-scorer/#run-container","text":"Note: Replace <version> with the version of the image you found from the previous step. docker run \\ --name rest-scorer \\ -v /path/to/local/pipeline.mojo:/mojos/pipeline.mojo:ro \\ -v /path/to/local/license.sig:/secrets/license.sig:ro \\ -p 8080:8080 \\ h2oai/rest-scorer:<version> Notice how the desired MOJO was mounted to the container: -v /path/to/local/pipeline.mojo:/mojos/pipeline.mojo:ro Notice how your H2O.ai DriverlessAI license was mounted to the container: -v /path/to/local/license.sig:/secrets/license.sig:ro Alternatively, you could pass in your license as an environment variable: First, export your license key. read -s DRIVERLESS_AI_LICENSE_KEY < /path/to/local/license.sig export DRIVERLESS_AI_LICENSE_KEY Note: Option -s , above, hides the echoing of your license so that its content is not written to logs. Now start a container. docker run \\ --name rest-scorer \\ -v /path/to/local/pipeline.mojo:/mojos/pipeline.mojo:ro \\ -e DRIVERLESS_AI_LICENSE_KEY \\ -p 8080:8080 \\ h2oai/rest-scorer:<version> See section Running above for information on how to score requests.","title":"Run Container"},{"location":"sql-jdbc-scorer/","text":"Driverless AI Deployment Template for Local Rest SQL Scorer \u00b6 This template contains an implementation of generic Java implementation for scoring Driverless AI Mojos( java runtime) against a SQL database. The application runs as a restful service and receives requests that include a SQL query and additional, appropriate parameters for scoring the table that results from the SQL query, and writing the preditions back to the database. The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring. The versions of software used to create the template like mojo runtime are listed here . Implementation \u00b6 The implementation leverages Spark APIs to handle data ingest/export via JDBC and Sparkling Water API's to manage distributed scoring in a Spark Session. This decision was made in order to allow for larger queries as Spark can manage data partitions very cleanly and avoid OOM errors. Building \u00b6 From the root project of this repository. You can run the following: ./gradlew build This will build the entire project and resultant jar file required for running the application will be available in the directory: build/libs Running \u00b6 In order to run the application you will need 4 files in addition to the jar file: Driverless AI License file - typically: license.sig Driverless AI Mojo - typically: pipeline.mojo JDBC configuration file - typically: jdbc.conf , example found here: jdbc.conf Note: the configuration file contains the expected JDBC driver class name org.postgresql.Driver which applies to the example below. JDBC Driver jar - the below example uses postgresql-42.2.5.jar , but this should be what ever JDBC driver jar is used by the database in question. These files will be added to the JVM via system properties using -D flag. Example run command: java -cp sql-jdbc-scorer-1.0.6-SNAPSHOT.jar \\ -Dmojo.path=pipeline.mojo \\ -Djdbc.config.path=jdbc.conf \\ -Dloader.path=postgresql-42.2.5.jar \\ -Dloader.main=ai.h2o.mojos.deploy.sql.db.ScorerApplication \\ org.springframework.boot.loader.PropertiesLauncher Score Request \u00b6 There are 2 methods of scoring. Both with the same end result: GET - takes input parameters in GET query and scores resultant dataset to the configured database POST - takes input json payload and scores resultant dataset to the configured database Parameter inputs for both methods: sqlQuery : String representation of a SQL Query. Ex. SELECT * FROM myTable outputTable : String representation of destination table for scorer to write to idColumn : numeric unique key for scorer to use for proper data partitioning. also can be used as key to join on with original table Note : this can be an empty string \"\"\" , but if no idColumn is provided there is a possibility that the application will run out of memory if a very large query is provided. Additionally, the resultant table will only contain the prediction columns making it hard to reference against the original table. saveMethod : one of [preview, append, overwrite, ignore, error] each with different behavior: preview: does not write to the database, only gives preview of resultant scored dataset in response All others are clearly documented as part of Spark API: here GET \u00b6 example query: http://localhost:8080/model/score?sqlQuery=%22SELECT%20*%20FROM%20creditcardtrain%22&outputTable=%22helloworld%22&idColumn=%22id%22 POST \u00b6 example query: curl -X POST -H \"Content-Type: application/json\" \\ -d '{\"query\": \"SELECT * FROM creditcardtrain LIMIT 10\", \"idColumn\": \"id\", \"saveMethod\": \"overwrite\", \"outputTable\": \"helloworld\"}' \\ http://localhost:8080/model/score Model ID \u00b6 You can get the UUID of the loaded pipeline by calling the following: $ curl http://localhost:8080/model/id API Inspection \u00b6 You can use SpringFox endpoints that allow both programmatic and manual inspection of the API: Swagger JSON representation for programmatic access: http://localhost:8080/v2/api-docs. The UI for manual API inspection: http://localhost:8080/swagger-ui.html.","title":"SQL JDBC Scorer"},{"location":"sql-jdbc-scorer/#driverless-ai-deployment-template-for-local-rest-sql-scorer","text":"This template contains an implementation of generic Java implementation for scoring Driverless AI Mojos( java runtime) against a SQL database. The application runs as a restful service and receives requests that include a SQL query and additional, appropriate parameters for scoring the table that results from the SQL query, and writing the preditions back to the database. The user needs to provide Driverless AI license key and model's pipeline.mojo file for scoring. The versions of software used to create the template like mojo runtime are listed here .","title":"Driverless AI Deployment Template for Local Rest SQL Scorer"},{"location":"sql-jdbc-scorer/#implementation","text":"The implementation leverages Spark APIs to handle data ingest/export via JDBC and Sparkling Water API's to manage distributed scoring in a Spark Session. This decision was made in order to allow for larger queries as Spark can manage data partitions very cleanly and avoid OOM errors.","title":"Implementation"},{"location":"sql-jdbc-scorer/#building","text":"From the root project of this repository. You can run the following: ./gradlew build This will build the entire project and resultant jar file required for running the application will be available in the directory: build/libs","title":"Building"},{"location":"sql-jdbc-scorer/#running","text":"In order to run the application you will need 4 files in addition to the jar file: Driverless AI License file - typically: license.sig Driverless AI Mojo - typically: pipeline.mojo JDBC configuration file - typically: jdbc.conf , example found here: jdbc.conf Note: the configuration file contains the expected JDBC driver class name org.postgresql.Driver which applies to the example below. JDBC Driver jar - the below example uses postgresql-42.2.5.jar , but this should be what ever JDBC driver jar is used by the database in question. These files will be added to the JVM via system properties using -D flag. Example run command: java -cp sql-jdbc-scorer-1.0.6-SNAPSHOT.jar \\ -Dmojo.path=pipeline.mojo \\ -Djdbc.config.path=jdbc.conf \\ -Dloader.path=postgresql-42.2.5.jar \\ -Dloader.main=ai.h2o.mojos.deploy.sql.db.ScorerApplication \\ org.springframework.boot.loader.PropertiesLauncher","title":"Running"},{"location":"sql-jdbc-scorer/#score-request","text":"There are 2 methods of scoring. Both with the same end result: GET - takes input parameters in GET query and scores resultant dataset to the configured database POST - takes input json payload and scores resultant dataset to the configured database Parameter inputs for both methods: sqlQuery : String representation of a SQL Query. Ex. SELECT * FROM myTable outputTable : String representation of destination table for scorer to write to idColumn : numeric unique key for scorer to use for proper data partitioning. also can be used as key to join on with original table Note : this can be an empty string \"\"\" , but if no idColumn is provided there is a possibility that the application will run out of memory if a very large query is provided. Additionally, the resultant table will only contain the prediction columns making it hard to reference against the original table. saveMethod : one of [preview, append, overwrite, ignore, error] each with different behavior: preview: does not write to the database, only gives preview of resultant scored dataset in response All others are clearly documented as part of Spark API: here","title":"Score Request"},{"location":"sql-jdbc-scorer/#get","text":"example query: http://localhost:8080/model/score?sqlQuery=%22SELECT%20*%20FROM%20creditcardtrain%22&outputTable=%22helloworld%22&idColumn=%22id%22","title":"GET"},{"location":"sql-jdbc-scorer/#post","text":"example query: curl -X POST -H \"Content-Type: application/json\" \\ -d '{\"query\": \"SELECT * FROM creditcardtrain LIMIT 10\", \"idColumn\": \"id\", \"saveMethod\": \"overwrite\", \"outputTable\": \"helloworld\"}' \\ http://localhost:8080/model/score","title":"POST"},{"location":"sql-jdbc-scorer/#model-id","text":"You can get the UUID of the loaded pipeline by calling the following: $ curl http://localhost:8080/model/id","title":"Model ID"},{"location":"sql-jdbc-scorer/#api-inspection","text":"You can use SpringFox endpoints that allow both programmatic and manual inspection of the API: Swagger JSON representation for programmatic access: http://localhost:8080/v2/api-docs. The UI for manual API inspection: http://localhost:8080/swagger-ui.html.","title":"API Inspection"}]}